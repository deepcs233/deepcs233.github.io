<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content="width=device-width, initial-scale=1">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */

    a {
      color: #1772d0;
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }

    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 20px
    }

    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 20px;
    }

    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 30px;
    }

    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
      font-weight: 700
    }

    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }

    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }

    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <style type="text/css">
    #sectiontohide {
      padding: 20px;
      background: #f0f0f0;
      width: 400px;
    }
  </style>
  <script type="text/javascript">
    function toggle_div_fun(id) {

      var divelement = document.getElementById(id);

      if (divelement.style.display == 'none')
        divelement.style.display = 'block';
      else
        divelement.style.display = 'none';
    }
  </script>
  <link rel="icon" type="image/png" href="pictures/CUHK.png">
  <title>Hao Shao</title>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="1200" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="70%" valign="middle">
              <p align="center">
                <name>Hao Shao &nbsp; &nbsp; 邵昊</name>
              </p>
              <p>
                I am an incoming PhD student in <a href="http://mmlab.ie.cuhk.edu.hk/">Multimedia Laboratory</a> in the 
                Chinese University of Hong Kong. I'm supervised by  <a href="http://www.ee.cuhk.edu.hk/~hsli/">Prof. Hongsheng Li</a> and <a href="https://www.ee.cuhk.edu.hk/~xgwang/">Prof.Xiaogang Wang</a>. 
              </p>
              <p>
                  Before that, I received my Master's degree from Tsinghua University in 2022,
                  and  my Bachelor degree from the University of Electronic Science and Technology of China
                in 2019.
              </p>
              <p>
                My research interests lie in the area of Autonomous Driving and Computer Vision. 
                Specifically, I'm pariticularly interested in end-to-end autonomous driving, trajectory prediction and video understanding. 
              </p>
              <p align=center>
                <a href="mailto:shaohao97@gmail.com"> Email </a> /
                <!-- <a href="https://www.linkedin.com/in/xudong-xu-5bb7b3173/"> LinkedIn </a> /-->
                <a href="https://scholar.google.com.hk/citations?user=D_ZLR1oAAAAJ"> Google Scholar </a> /
                <a href="https://github.com/deepcs233"> Github </a>
              </p>
            </td>
            <td width="30%">
              <img src="pictures/shaohao.png" width="220">
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Education</heading>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellpadding="10">
          <tr>
            <td width="25%" align="center">
              <img src="pictures/CUHK.png" alt="CUHK" width="95" height="80">
            </td>
            <td width="75%" valign="top">
              <p>
                <strong>Aug. 2023 -   </strong>, Department of Electronic Engineering,
                <i>
                  <b>the Chinese University of Hong Kong</b>
                </i></p>
              <p>PhD Student</br>
              </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellpadding="10">
          <tr>
            <td width="25%" align="center">
              <img src="pictures/thu.png" alt="THU" width="90" height="90">
            </td>
            <td width="75%" valign="top">
              <p>
                <strong>Sept. 2019 - Jun. 2022 </strong>, School of Software Engineering,
                <i>
                  <b>Tsinghua University</b>
                </i></p>
              <p>Master</br>
              </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellpadding="10">
          <tr>
            <td width="25%" align="center">
              <img src="pictures/uestc.png" alt="UESTC" width="90" height="90">
            </td>
            <td width="75%" valign="top">
              <p>
                <strong>Sept. 2015 - Jun. 2019 </strong>, School of Software Engineering,
                <i>
                  <b>University of Electronic Science and Technology of China</b>
                </i></p>
              <p>Bachelor   GPA: 3.98/4</br>
              </p>
            </td>
          </tr>
        </table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="10" cellpadding="10">
          <tr>
            <td width="35%" align="center">
              <img src="pictures/asprl2023.png" alt="asprl" width="400" height="180">
            </td>
            <td width="65%" valign="top">
              <p>
                <papertitle>Efficient Reinforcement Learning for Autonomous Driving with Parameterized Skills and Priors</papertitle>
                <br>
                Letian Wang, Jie Liu, <strong>Hao Shao</strong>, Wenshuo Wang, Ruobing Chen, Yu Liu, Steven L Waslander
                <br>
                <em>Robotics: Science and Systems (<strong>RSS</strong>)</em>, 2023
                <br>
                <a href="https://arxiv.org/abs/2305.04412">[paper]</a>
                <a href="https://github.com/Letian-Wang/asaprl">[code]</a>
                <br>
                <p>
                   We present an efficient reinforcement learning (ASAP-RL) that simultaneously leverages parameterized motion skills and expert priors for autonomous vehicles to navigate in complex dense traffic.
                </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="10" cellpadding="10">
          <tr>
            <td width="35%" align="center">
              <img src="pictures/reasonnet2023.png" alt="reasonnet" width="400" height="200">
            </td>
            <td width="65%" valign="top">
              <p>
                <papertitle>ReasonNet: End-to-End Driving with Temporal and Global Reasoning</papertitle>
                <br>
                <strong>Hao Shao</strong>, Letian Wang, Ruobing Chen, Steven L Waslander, Hongsheng Li, Yu Liu
                <br>
                <em>Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2023
                <br>
                <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Shao_ReasonNet_End-to-End_Driving_With_Temporal_and_Global_Reasoning_CVPR_2023_paper.html">[paper]</a>
                <br>
                <p>
                    We present ReasonNet, a novel end-to-end driving framework that extensively exploits both temporal and global information of the driving scene.
                </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="10" cellpadding="10">
          <tr>
            <td width="35%" align="center">
              <img src="pictures/interfuser2022.png" alt="interfuser" width="400" height="150">
            </td>
            <td width="65%" valign="top">
              <p>
                <papertitle>Safety-enhanced autonomous driving using interpretable sensor fusion transformer</papertitle>
                <br>
                <strong>Hao Shao</strong>, Letian Wang, Ruobing Chen, Hongsheng Li, Yu Liu
                <br>
                <em>Conference on Robot Learning (<strong>CoRL</strong>)</em>, 2022
                <br>
                <a href="https://arxiv.org/abs/2207.14024">[paper]</a>
                <a href="https://github.com/opendilab/InterFuser">[code]</a>
                <br>
                <p>
                    We propose a safety-enhanced autonomous driving framework, named Interpretable Sensor Fusion Transformer (InterFuser), to fully process and fuse information from multi-modal multi-view sensors for achieving comprehensive scene understanding and adversarial event detection.
                </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="10" cellpadding="10">
          <tr>
            <td width="35%" align="center">
              <img src="pictures/antialising2021.png" alt="antialiasing" width="400" height="170">
            </td>
            <td width="65%" valign="top">
              <p>
                <papertitle>Blending anti-aliasing into vision transformer</papertitle>
                <br>
                Shengju Qian, <strong>Hao Shao</strong>, Yi Zhu, Mu Li, Jiaya Jia
                <br>
                <em>Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, 2021
                <br>
                <a href="https://proceedings.neurips.cc/paper/2021/hash/2b3bf3eee2475e03885a110e9acaab61-Abstract.html">[paper]</a>
                <br>
                <p>
                    We propose a plug-and-play Aliasing-Reduction Module (ARM) to alleviate the problem of aliasing in vision transformer.
                </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="10" cellpadding="10">
          <tr>
            <td width="35%" align="center">
              <img src="pictures/tin2020.png" alt="tin" width="400" height="200">
            </td>
            <td width="65%" valign="top">
              <p>
                <papertitle>Temporal interlacing network</papertitle>
                <br>
                <strong>Hao Shao</strong>, Shengju Qian, Yu Liu
                <br>
                <em>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</em>, 2020
                <br>
                <a href="https://arxiv.org/abs/2001.06499">[paper]</a>
                <a href="https://github.com/deepcs233/TIN">[code]</a>
                <br>
                <p>
                    We present a simple yet powerful operator – temporalinterlacing network (TIN). Instead of learning the temporal features, TIN fuses the two kinds of information by interlacing spatial representations from the past to the future, and vice versa.
                </p>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Industry Experience</heading>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellpadding="10">
          <tr>
            <td width="25%" align="center">
              <img src="pictures/sensetime.png" alt="Sensetime" width="180" height="100">
            </td>
            <td width="75%" valign="top">
              <p>
                <strong>Apr 2019 - Now</strong>,
                <i>
                  <b>XLab</b>
                </i></p>
                Researcher(intern).  <i>Beijing, China</i>
              </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellpadding="10">
          <tr>
            <td width="25%" align="center">
              <img src="pictures/tencent.png" alt="ByteDance" width="220" height="100">
            </td>
            <td width="75%" valign="top">
              <p>
                <strong>Sep 2018 - Apr 2019</strong>,
                <i>
                  <b>Computer Vision</b>
                </i></p>
                Research intern.  <i>Shenzhen, China</i>
              </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellpadding="10">
          <tr>
            <td width="25%" align="center">
              <img src="pictures/bytedance.png" alt="ByteDance" width="180" height="100">
            </td>
            <td width="75%" valign="top">
              <p>
                <strong>Jul 2017 - May 2018</strong>,
                <i>
                  <b>Recommend System</b>
                </i></p>
                Research intern.  <i>Beijing, China</i>
              </p>
            </td>
          </tr>
        </table>

        <!--
        <table width="100%" align="center" border="0" cellspacing="10" cellpadding="20">
          <tr>
            <td>
              <heading>Academic Activities</heading>
            </td>
          </tr>
        </table>
        <ul>
          <li>
            <p>I serve as a reviewer for BMVC, CVPR, ICCV, NeurIPS, ICML, AAAI, etc.
          </li>
        </ul>
        -->
        <!-- Honors and Awards ======================================== -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Honors and Awards</heading>
            </td>
          </tr>
        </table>
        <ul>
          <li>
            <p>Postgraduate Scholarship, the Chinese University of Hong Kong, 2023 ~ now</p>
          </li>
          <li>
              <p>The First Prize, <a href="https://leaderboard.carla.org/leaderboard/"> CARLA Autonomous Driving Challenge (sensor track)</a>, 2022</p>
          </li>
          <li>
            <p>The First Prize, CVPR20 ActivityNet Challenge (<a href="http://activity-net.org/challenges/2020/tasks/guest_kinetics.html/">Kinetics700</a> track and  <a href="https://www.youtube.com/watch?v=zJPEmG3LCH4&amp;list=PLw6H4u-XW8siSxqdRVcD5aBn3OTuA7M7x/">AVA track</a>), 2020</p>
          </li>
          <li>
            <p>The First Prize, <a href="http://moments.csail.mit.edu/results2019.html/">ICCV19 Multi-Moments in Time (MIT) Challenge</a>, 2019</p>
          </li>
          <li>
            <p>Outstanding Graduate of UESTC, 2019</p>
          </li>
          <li>
            <p>National Scholarship, University of Electronic Science and Technology of China, 2017</p>
          </li>
        </ul>
        <br />
        <!-- Footer ================================================== -->
        <hr>

        <footer class="footer">
          <div class="container">
            <p>
              &nbsp;&nbsp;&nbsp;Updated Jul. 2023</p>
            </p>
            <p align=right>
              <a href="https://ai.stanford.edu/~kaidicao/"> Page Template </a>
              <a class="pull-right" href="#">
                  <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=n&d=VkYT7USR1EDQkDTDlP7q_8FwHSe_Y6-QtMU3WeV4Wgc&co=2d78ad&cmo=3acc3a&cmn=ff5353&ct=ffffff"></script>
              </a>
            </p>
          </div>
        </footer>

		<!-- Google tag (gtag.js) -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=G-SCMVBJM8DX"></script>
		<script>
		  window.dataLayer = window.dataLayer || [];
		  function gtag(){dataLayer.push(arguments);}
		  gtag('js', new Date());

		  gtag('config', 'G-SCMVBJM8DX');
		</script>

      </td>
    </tr>
  </table>
</body>

</html>
